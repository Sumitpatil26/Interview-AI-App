# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ONpoOqW-kUurs3zdKxVWZ2eW1EdG61UO

**Exam - Data Analytics 2: Text Mining and Natural Language Processing**

**Sumit Nivrutti Patil - 100003409**

**Section A - Data Analysis & Preprocessing:**

**1. Load the data:**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load training dataset
train_df = pd.read_csv('/content/train.csv')

# Show the first few rows
train_df.head()

# Number of unique labels
unique_labels = train_df['Labels'].unique()
print(f"Number of unique labels: {len(unique_labels)}")
print("Unique labels:", unique_labels)

# Class distribution
label_counts = train_df['Labels'].value_counts()

# Bar plot
plt.figure(figsize=(12, 6))
sns.barplot(x=label_counts.index, y=label_counts.values)
plt.title("Class Distribution")
plt.ylabel("Count")
plt.xlabel("Labels")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""**2. Text Cleaning and Tokenization:**"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Download required NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')

stop_words = set(stopwords.words('english'))

def clean_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove special characters and numbers
    text = re.sub(r'[^a-z\s]', '', text)
    # Tokenize
    tokens = word_tokenize(text)
    # Remove stopwords
    filtered_tokens = [word for word in tokens if word not in stop_words]
    return filtered_tokens

# Apply to the training data
train_df['clean_tokens'] = train_df['Interview Text'].apply(clean_text)

# Show sample
train_df[['Interview Text', 'clean_tokens']].head()

"""**3. Word Frequency Plots & Word Clouds per Class:**"""

from collections import Counter
from wordcloud import WordCloud

def plot_wordcloud(label):
    all_words = train_df[train_df['Labels'] == label]['clean_tokens'].sum()
    word_freq = Counter(all_words)
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"Word Cloud for Class: {label}")
    plt.show()

# Example: Plot for first 3 classes
for label in unique_labels[:3]:
    plot_wordcloud(label)

"""**4. Token Frequency Plot:**"""

import itertools

# Flatten all tokens
all_tokens = list(itertools.chain(*train_df['clean_tokens'].tolist()))
token_freq = Counter(all_tokens).most_common(20)

# Plot
words, freqs = zip(*token_freq)
plt.figure(figsize=(10,5))
sns.barplot(x=list(words), y=list(freqs))
plt.title("Top 20 Frequent Words in Training Data")
plt.xticks(rotation=45)
plt.ylabel("Frequency")
plt.show()

"""**Section B - Model Development and Evaluation:**

**1. TF-IDF + Logistic Regression Model:**
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
import matplotlib.pyplot as plt

# Rejoin tokens for TF-IDF input
train_df['clean_text'] = train_df['clean_tokens'].apply(lambda tokens: ' '.join(tokens))

# Load validation data
val_df = pd.read_csv('/content/val.csv')
val_df['Interview Text'] = val_df['Interview Text'].astype(str)

# Preprocess validation set
val_df['clean_tokens'] = val_df['Interview Text'].apply(clean_text)
val_df['clean_text'] = val_df['clean_tokens'].apply(lambda tokens: ' '.join(tokens))

# Vectorize
tfidf = TfidfVectorizer(max_features=5000)
X_train = tfidf.fit_transform(train_df['clean_text'])
X_val = tfidf.transform(val_df['clean_text'])

y_train = train_df['Labels']
y_val = val_df['Labels']

# Train logistic regression
lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_val)

# Evaluation
print("Logistic Regression Report:")
print(classification_report(y_val, y_pred_lr))
print("Accuracy:", accuracy_score(y_val, y_pred_lr))
print("F1 Score (weighted):", f1_score(y_val, y_pred_lr, average='weighted'))

# Confusion matrix
cm = confusion_matrix(y_val, y_pred_lr, labels=lr_model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr_model.classes_)
disp.plot(xticks_rotation=45)
plt.title("Logistic Regression Confusion Matrix")
plt.show()

"""**2. Transformer-based Model (BERT):**"""

import os
os.environ["WANDB_MODE"] = "disabled"
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from transformers import DataCollatorWithPadding
from sklearn.preprocessing import LabelEncoder
import torch
from datasets import Dataset

# Label encoding
label_encoder = LabelEncoder()
train_df['labels_enc'] = label_encoder.fit_transform(train_df['Labels'])
val_df['labels_enc'] = label_encoder.transform(val_df['Labels'])

# Load BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-cased')

def tokenize_function(example):
    return tokenizer(example["Interview Text"], truncation=True)

# Convert to HuggingFace Dataset
train_dataset = Dataset.from_pandas(train_df[['Interview Text', 'labels_enc']])
val_dataset = Dataset.from_pandas(val_df[['Interview Text', 'labels_enc']])

# Rename the 'labels_enc' column to 'labels'
train_dataset = train_dataset.rename_column('labels_enc', 'labels')
val_dataset = val_dataset.rename_column('labels_enc', 'labels')

train_dataset = train_dataset.map(tokenize_function, batched=True)
val_dataset = val_dataset.map(tokenize_function, batched=True)

# Model
num_labels = len(label_encoder.classes_)
model = BertForSequenceClassification.from_pretrained("bert-base-cased", num_labels=num_labels)

# Training setup
training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="epoch",
    logging_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=5,
    learning_rate=1e-5,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model='eval_f1',
)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=lambda p: {
        'accuracy': accuracy_score(p.label_ids, p.predictions.argmax(-1)),
        'f1': f1_score(p.label_ids, p.predictions.argmax(-1), average='weighted')
    }
)

# Train BERT
trainer.train()

# Predictions
bert_preds = trainer.predict(val_dataset)
y_pred_bert = bert_preds.predictions.argmax(axis=-1)

print("BERT Classification Report:")
print(classification_report(val_df['labels_enc'], y_pred_bert, target_names=[str(cls) for cls in label_encoder.classes_]))

# Plot confusion matrix
cm = confusion_matrix(val_df['labels_enc'], y_pred_bert)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)
disp.plot(xticks_rotation=45)
plt.title("BERT Confusion Matrix")
plt.show()

import os
os.environ["WANDB_MODE"] = "disabled"
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from transformers import DataCollatorWithPadding
from sklearn.preprocessing import LabelEncoder
import torch
from datasets import Dataset

# Label encoding
label_encoder = LabelEncoder()
train_df['labels_enc'] = label_encoder.fit_transform(train_df['Labels'])
val_df['labels_enc'] = label_encoder.transform(val_df['Labels'])

# Load BERT tokenizer
tokenizer = BertTokenizer.from_pretrained("sumit2603/bert-sports-interview-classifier")

def tokenize_function(example):
    return tokenizer(example["Interview Text"], truncation=True)

# Convert to HuggingFace Dataset
train_dataset = Dataset.from_pandas(train_df[['Interview Text', 'labels_enc']])
val_dataset = Dataset.from_pandas(val_df[['Interview Text', 'labels_enc']])

# Rename the 'labels_enc' column to 'labels'
train_dataset = train_dataset.rename_column('labels_enc', 'labels')
val_dataset = val_dataset.rename_column('labels_enc', 'labels')

train_dataset = train_dataset.map(tokenize_function, batched=True)
val_dataset = val_dataset.map(tokenize_function, batched=True)

# Model
num_labels = len(label_encoder.classes_)
model = BertForSequenceClassification.from_pretrained("sumit2603/bert-sports-interview-classifier", num_labels=num_labels)

# Training setup
training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="epoch",
    logging_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    load_best_model_at_end=True,
)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=lambda p: {
        'accuracy': accuracy_score(p.label_ids, p.predictions.argmax(-1)),
        'f1': f1_score(p.label_ids, p.predictions.argmax(-1), average='weighted')
    }
)

# Train BERT
trainer.train()

# Predictions
bert_preds = trainer.predict(val_dataset)
y_pred_bert = bert_preds.predictions.argmax(axis=-1)

print("BERT Classification Report:")
print(classification_report(val_df['labels_enc'], y_pred_bert, target_names=[str(cls) for cls in label_encoder.classes_]))

# Plot confusion matrix
cm = confusion_matrix(val_df['labels_enc'], y_pred_bert)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)
disp.plot(xticks_rotation=45)
plt.title("BERT Confusion Matrix")
plt.show()

model.save_pretrained("./saved_bert_model")
tokenizer.save_pretrained("./saved_bert_model")

"""**3. Feature Importance for Logistic Regression:**"""

# Show top words contributing to each class
feature_names = tfidf.get_feature_names_out()
top_n = 10

for i, class_label in enumerate(lr_model.classes_):
    top_indices = lr_model.coef_[i].argsort()[-top_n:]
    print(f"Top features for class '{class_label}':")
    print([feature_names[j] for j in top_indices][::-1])
    print()

"""**4. Visual Reports — Confusion Matrix and Label Distribution:**

Confusion Matrix (again for saving)
"""

import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(val_df['labels_enc'], y_pred_bert)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_)
plt.title("Confusion Matrix – BERT")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("bert_confusion_matrix.png")
plt.show()

"""Predicted Label Distribution (on Test Set)"""

plt.figure(figsize=(10, 5))
sns.countplot(x=test_labels_decoded, order=pd.Series(test_labels_decoded).value_counts().index)
plt.title("Predicted Label Distribution – BERT on Test Set")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("bert_predicted_label_distribution.png")
plt.show()

"""**Section C - Text Generation:**"""

!pip install -q transformers

from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

# Load model & tokenizer
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
tokenizer.pad_token = tokenizer.eos_token
model = GPT2LMHeadModel.from_pretrained("gpt2").to("cuda" if torch.cuda.is_available() else "cpu")
device = next(model.parameters()).device

def build_prompt(category, question):
    return f"""Category: {category}
Q: {question}
A:"""

def generate_response(prompt, max_length=100):
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    outputs = model.generate(
        **inputs,
        max_new_tokens=max_length,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        temperature=0.9,
        pad_token_id=tokenizer.eos_token_id
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True).split("A:")[-1].strip()

examples = [
    ("post_game_reaction", "What are your thoughts on today's performance?"),
    ("injury_update", "Can you tell us about your current physical condition?"),
    ("contract_talk", "Are there any updates on your free agency situation?"),
    ("team_dynamics", "How is the chemistry in the locker room right now?"),
    ("playoff_expectations", "How confident are you going into the playoffs?")
]

for cat, q in examples:
    prompt = build_prompt(cat, q)
    response = generate_response(prompt)
    print(f"🗂️ Interview Category: {cat}\n❓ Q: {q}\n💬 A: {response}\n{'-'*60}")

# Imports
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

# Load GPT-2 model and tokenizer
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
tokenizer.pad_token = tokenizer.eos_token
model = GPT2LMHeadModel.from_pretrained("gpt2")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Prompt template
def build_prompt(category, question):
    return f"Category: {category}\nQ: {question}\nA:"

# Text generation function
def generate_response(prompt, max_length=100):
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    outputs = model.generate(
        **inputs,
        max_new_tokens=max_length,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        temperature=0.9,
        pad_token_id=tokenizer.eos_token_id
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True).split("A:")[-1].strip()

# List of example interview prompts
examples = [
    ("post_game_reaction", "What are your thoughts on today’s performance?"),
    ("injury_update", "How is your recovery coming along?"),
    ("contract_talk", "Are you planning to re-sign with the team next season?"),
    ("team_dynamics", "How would you describe the current locker room atmosphere?"),
    ("playoff_expectations", "Do you feel prepared heading into the postseason?")
]

# Generate and display responses
for category, question in examples:
    prompt = build_prompt(category, question)
    response = generate_response(prompt)
    print(f"🗂️ Interview Category: {category}")
    print(f"❓ Q: {question}")
    print(f"💬 A: {response}")
    print("-" * 70)

"""**Reflection on AI-Generated Interview Responses:**

Using AI to generate interview answers can be both helpful and risky for sports journalists and broadcasters.

On the helpful side, it can save time. For example, AI can be used to come up with possible answers before an actual interview, help with writing summaries, or even create sample quotes for previews. It’s also useful for quickly translating or drafting content in different languages.

But there are also some concerns. If someone uses AI to create quotes and doesn’t make it clear that they’re fake, it could mislead people. It might look like a real player said something when they didn’t. This could cause confusion or even damage someone’s reputation. Also, if people rely too much on AI, it might take away from real conversations and reporting.

So overall, AI can be a useful tool in sports media, but it should be used carefully and honestly. It’s important to make sure the audience knows when something was written by AI and when it came from a real person.

**Section D - Visualization:**
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns

# Reuse cleaned text
texts = train_df['clean_text']

# Step 1: TF-IDF Vectorization
vectorizer = TfidfVectorizer(max_features=3000)
X = vectorizer.fit_transform(texts)

# Step 2: KMeans Clustering (you can tune n_clusters later)
n_clusters = 8
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
train_df['cluster'] = kmeans.fit_predict(X)

# Step 3: Reduce dimensions for visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X.toarray())

# Step 4: Plot clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=train_df['cluster'], palette='tab10')
plt.title("Interview Topic Clusters (PCA)")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.legend(title="Cluster")
plt.tight_layout()
plt.savefig("topic_clusters.png")
plt.show()

# Print cluster count
print(f"Total number of topic clusters: {n_clusters}")

"""**Description of My Approach:**

I wanted to group similar interview texts together based on what they were talking about. First, I turned the cleaned-up text into numbers using something called TF-IDF, which helps find important words in each interview.

Next, I used a method called KMeans to sort the interviews into different groups, or clusters, based on those words. Since the data had too many dimensions to look at directly, I used PCA to reduce it to just two, which made it easier to draw a chart.

Then I created a scatter plot to show how the interviews were grouped. Each color in the chart shows a different topic cluster. I also counted how many clusters there were in total.

**Section E - Streamlit Integration and Deployment:**

**1. Transcript Classification Tool:**
"""

!pip install streamlit
import streamlit as st
from transformers import BertTokenizer, BertForSequenceClassification
import torch
import numpy as np
import pickle

# Load tokenizer & model
@st.cache_resource
def load_classifier():
    tokenizer = BertTokenizer.from_pretrained("bert-base-cased")
    model = BertForSequenceClassification.from_pretrained("./saved_bert_model")
    return tokenizer, model

tokenizer, model = load_classifier()

# Classification function
def classify_transcript(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    outputs = model(**inputs)
    pred_label = torch.argmax(outputs.logits, dim=1).item()
    return pred_label

"""**2. Question + Category → Response Generator:**"""

from transformers import GPT2LMHeadModel, GPT2Tokenizer

@st.cache_resource
def load_gpt2():
    tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
    tokenizer.pad_token = tokenizer.eos_token
    model = GPT2LMHeadModel.from_pretrained("gpt2")
    return tokenizer, model

gpt2_tokenizer, gpt2_model = load_gpt2()

def generate_response(category, question):
    prompt = f"Category: {category}\nQ: {question}\nA:"
    inputs = gpt2_tokenizer(prompt, return_tensors="pt").to(gpt2_model.device)
    outputs = gpt2_model.generate(**inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95)
    return gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True).split("A:")[-1].strip()

"""**3. Embedding Visualization with UMAP or t-SNE:**"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.manifold import TSNE  # or use UMAP
import pandas as pd

# Use your original train_df['Interview Text'] and train_df['Label']
texts = train_df['Interview Text']
labels = train_df['Labels']

# TF-IDF
vectorizer = TfidfVectorizer(max_features=3000)
X = vectorizer.fit_transform(texts)

# t-SNE (or use UMAP if installed)
tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X.toarray())

# Build DataFrame for plotting
embedding_df = pd.DataFrame({
    'x': X_tsne[:, 0],
    'y': X_tsne[:, 1],
    'label': labels,
    'sample_text': texts.str.slice(0, 100)  # Optional: shorten text for tooltip
})

# Save to CSV for Streamlit app
embedding_df.to_csv("embedding_data.csv", index=False)

import pandas as pd
import plotly.express as px

# Load pre-computed data (e.g., UMAP embeddings)
@st.cache_data
def load_embeddings():
    df = pd.read_csv("embedding_data.csv")  # should contain: x, y, label, sample_text
    return df

embeddings_df = load_embeddings()

def show_plot():
    fig = px.scatter(
        embeddings_df,
        x="x", y="y",
        color="label",
        hover_data=["sample_text"],
        title="Transcript Embedding Clusters"
    )
    st.plotly_chart(fig, use_container_width=True)

"""**Build the App Layout:**"""

st.title("🏟️ Sports Interview AI Dashboard")

# Tabs or sections
section = st.sidebar.radio("Choose Feature", ["Transcript Classification", "Q&A Generator", "Visualization"])

if section == "Transcript Classification":
    st.header("📌 Classify Interview Transcript")
    text_input = st.text_area("Paste full transcript:")
    if st.button("Classify"):
        if text_input.strip():
            pred = classify_transcript(text_input)
            st.success(f"Predicted Category: {pred}")
        else:
            st.warning("Please enter transcript text.")

elif section == "Q&A Generator":
    st.header("🧠 AI Interview Response Generator")
    category = st.selectbox("Select Category", ["post_game_reaction", "injury_update", "contract_talk", "team_dynamics", "playoff_expectations"])
    question = st.text_input("Enter your question:")
    if st.button("Generate Answer"):
        if question.strip():
            answer = generate_response(category, question)
            st.markdown("**💬 AI Response:**")
            st.write(answer)
        else:
            st.warning("Please enter a question.")

elif section == "Visualization":
    st.header("📊 Transcript Embedding Explorer")
    show_plot()

!pip install -q huggingface_hub
from huggingface_hub import login

# Log in with your Hugging Face token
login()

from transformers import BertForSequenceClassification, BertTokenizer
from huggingface_hub import HfApi

# Load from your saved folder
model = BertForSequenceClassification.from_pretrained("./saved_bert_model")
tokenizer = BertTokenizer.from_pretrained("./saved_bert_model")

# Replace with your model name
model_name = "bert-sports-interview-classifier"

# Push to Hugging Face Hub
model.push_to_hub(model_name)
tokenizer.push_to_hub(model_name)

"""**Section F - Submission and Evaluation:**

**1. submission.csv — Predictions on test.csv:**
"""

# Load and clean test data
test_df = pd.read_csv('/content/test.csv')
test_df['Interview Text'] = test_df['Interview Text'].astype(str)
test_df['Interview Text'] = test_df['Interview Text'].fillna('')

# Tokenize
test_dataset = Dataset.from_pandas(test_df[['ID', 'Interview Text']])
test_dataset = test_dataset.map(tokenize_function, batched=True)

# Predict
test_preds = trainer.predict(test_dataset)
test_preds_labels = test_preds.predictions.argmax(axis=1)
test_labels_decoded = label_encoder.inverse_transform(test_preds_labels)

# Save to CSV
submission_df = pd.DataFrame({
    'ID': test_df['ID'],
    'Label': test_labels_decoded
})
submission_df.to_csv('submission.csv', index=False)

print("✅ submission.csv saved.")

import pandas as pd
import numpy as np
import json
from sklearn.metrics import accuracy_score, f1_score

# Load test and ground truth data
test_df = pd.read_csv("/content/test.csv")  # contains: ID, Interview Text
ground_truth = pd.read_csv("/content/val.csv")  # contains: ID, Labels

# Tokenize test set (reusing your existing tokenizer and model)
test_df['Interview Text'] = test_df['Interview Text'].astype(str)
test_dataset = Dataset.from_pandas(test_df[['ID', 'Interview Text']])

# Your tokenize_function expects 'Interview Text'
test_dataset = test_dataset.map(tokenize_function, batched=True)

# Predict
test_output = trainer.predict(test_dataset)
test_preds = np.argmax(test_output.predictions, axis=1)
test_labels = label_encoder.inverse_transform(test_preds)

# Save submission.csv
submission_df = pd.DataFrame({
    'ID': test_df['ID'],
    'Labels': test_labels
})
submission_df.to_csv("submission.csv", index=False)
print("✅ Saved submission.csv")

"""**2. results.json — Store Accuracy and F1 Score:**"""

import json

# Compute final scores for both models
logistic_f1 = f1_score(y_val, y_pred_lr, average='weighted')
logistic_acc = accuracy_score(y_val, y_pred_lr)

bert_f1 = f1_score(val_df['labels_enc'], y_pred_bert, average='weighted')
bert_acc = accuracy_score(val_df['labels_enc'], y_pred_bert)

# Save both to results.json
results = {
    "logistic_regression": {
        "f1_score": round(logistic_f1, 4),
        "accuracy": round(logistic_acc, 4)
    },
    "bert": {
        "f1_score": round(bert_f1, 4),
        "accuracy": round(bert_acc, 4)
    }
}

with open("results.json", "w") as f:
    json.dump(results, f, indent=4)

print("✅ results.json saved.")

import json
from sklearn.metrics import accuracy_score, f1_score

# Load ground truth
ground_truth_df = pd.read_csv('/content/ground_truth.csv')

# Match ground truth with predicted labels by ID
merged_df = pd.merge(ground_truth_df, submission_df, on="ID")
y_true = merged_df["Labels_x"]
y_pred = merged_df["Labels_y"]

# Calculate metrics
acc = accuracy_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred, average='weighted')

# Save to JSON in required format
results = {
    "f1_score": round(f1, 5),
    "accuracy": round(acc, 5)
}

with open("results.json", "w") as f:
    json.dump(results, f, indent=2)

print("✅ results.json saved.")
print(results)